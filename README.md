# ğŸŒŒ NASA Exoplanet Detection AI

> Advanced machine learning system for identifying exoplanet candidates from NASA mission data (Kepler, K2, TESS)

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.0+-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ¯ Overview

This project combines state-of-the-art ensemble learning with an intuitive web interface to detect exoplanets from NASA telescope data. The system features model comparison, explainability through SHAP, and comprehensive validation capabilities.

### Key Capabilities

| Feature | Description |
|---------|-------------|
| ğŸ¤– **Ensemble Models** | LightGBM, RandomForest, ExtraTrees, AdaBoost, XGBoost, Stacking |
| ğŸ” **Model Selection** | Per-prediction model choice with full comparison mode |
| ğŸ“Š **Batch Processing** | CSV upload with multi-model analysis |
| âœ… **External Validation** | Independent TOI & K2 dataset testing |
| ğŸšï¸ **Threshold Control** | Adjustable decision boundaries with probability calibration |
| ğŸ’¡ **Explainability** | SHAP-powered feature importance analysis |
| ğŸ”§ **Retraining** | Quick parameter tuning for RandomForest and LightGBM |
| ğŸ“ˆ **Reporting** | Exportable HTML performance reports |

---

## ğŸ“‚ Project Structure

```
nasa-exoplanet-detection/
â”‚
â”œâ”€â”€ ğŸ data_preprocessing.py      # Data loading, cleaning, feature engineering
â”œâ”€â”€ ğŸ¤– models.py                  # Model creation, training, evaluation
â”œâ”€â”€ ğŸš€ train_models.py            # End-to-end training pipeline
â”œâ”€â”€ ğŸŒ web_app.py                 # Streamlit web application
â”œâ”€â”€ ğŸ”§ normalize_external_csvs.py # TOI/K2 CSV normalizer
â”œâ”€â”€ ğŸ§ª generate_test_data.py      # Mock CSV generators
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ Kepler Objects of Interest (KOI).csv
â”‚   â”œâ”€â”€ TESS Objects of Interest (TOI).csv
â”‚   â””â”€â”€ K2 Planets and Candidates.csv
â”‚
â”œâ”€â”€ ğŸ“ reports/                   # Generated performance reports
â”œâ”€â”€ ğŸ“ models/                    # Trained model files (*.joblib)
â”‚
â””â”€â”€ ğŸ“„ requirements.txt
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Environment Setup

```bash
# Create virtual environment
python -m venv nasa_exoplanet_env

# Activate environment
# Windows:
nasa_exoplanet_env\Scripts\activate
# Linux/Mac:
source nasa_exoplanet_env/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Prepare Datasets

Place the following files in your project root (exact filenames required):

- âœ… `Kepler Objects of Interest (KOI).csv`
- âœ… `TESS Objects of Interest (TOI).csv`
- âœ… `K2 Planets and Candidates.csv`

> ğŸ’¡ **Tip**: Download datasets from [NASA Exoplanet Archive](https://exoplanetarchive.ipst.edu/)

### 3ï¸âƒ£ Train Models (Optional)

```bash
python train_models.py
```

This generates model files (`exoplanet_models_*.joblib`) and performance reports.

### 4ï¸âƒ£ Launch Application

```bash
streamlit run web_app.py
```

ğŸŒ Open your browser to `http://localhost:8501`

---

## ğŸ–¥ï¸ Application Features

### ğŸ“± Navigation Pages

<table>
<tr>
<td width="30%"><b>ğŸ  Home</b></td>
<td>Overview dashboard with quick statistics</td>
</tr>
<tr>
<td><b>ğŸ”® Make Predictions</b></td>
<td>
â€¢ <b>Manual Entry:</b> Input parameters, select model, adjust threshold<br>
â€¢ <b>Upload CSV:</b> Batch predictions with downloadable results
</td>
</tr>
<tr>
<td><b>ğŸ“Š Model Performance</b></td>
<td>Comprehensive metrics, charts, and HTML export</td>
</tr>
<tr>
<td><b>ğŸ”¬ Feature Analysis</b></td>
<td>Feature importance rankings and SHAP explanations</td>
</tr>
<tr>
<td><b>âœ¨ External Validation</b></td>
<td>Independent testing on TOI and K2 datasets</td>
</tr>
<tr>
<td><b>â„¹ï¸ About</b></td>
<td>Project background and implementation details</td>
</tr>
</table>

---

## ğŸ§¬ External Validation System

The application validates models against independent TESS TOI and K2 datasets, reporting:
- Accuracy
- Precision
- Recall
- F1 Score
- ROC-AUC

### ğŸ“‹ Data Requirements

#### TOI Dataset
- **Required Column:** `tfopwg_disp`
- **Valid Values:** `CP`, `PC`, `FP`

#### K2 Dataset
- **Required Column:** `disposition`
- **Valid Values:** `CONFIRMED`, `CANDIDATE`, `FALSE POSITIVE`

### ğŸ”„ Feature Mapping

The system automatically maps external dataset features to KOI schema:

```
TOI/K2 Feature    â†’    KOI Feature
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
pl_orbper         â†’    koi_period
pl_trandurh       â†’    koi_duration
st_teff           â†’    koi_steff
... (automatic mapping)
```

### ğŸ’¾ Using Copy Files (Recommended)

For safety, create copies of external datasets:
- `TESS Objects of Interest (TOI) copy.csv`
- `K2 Planets and Candidates copy.csv`

Run normalization utility:

```bash
python normalize_external_csvs.py
```

This script:
- âœ… Standardizes label values
- âœ… Trims whitespace
- âœ… Fills missing RA/Dec from alternatives

### ğŸ”§ Troubleshooting "No external validation data"

1. **Initialize processor:** Open "Make Predictions" page once
2. **Verify files:** Ensure required CSV files are present
3. **Check labels:** Confirm disposition columns have valid values
4. **Run normalizer:** Execute `normalize_external_csvs.py`

---

## âš™ï¸ Advanced Features

### ğŸšï¸ Threshold Adjustment

Balance between discovery and precision:

| Setting | Effect |
|---------|--------|
| **Lower Threshold** | More candidates detected (â†‘ Recall, â†“ Precision) |
| **Higher Threshold** | Fewer false alarms (â†“ Recall, â†‘ Precision) |

### ğŸ“ Probability Calibration

Enable **Isotonic Calibration** for:
- Improved probability estimates
- Better ranking of candidates
- Enhanced threshold reliability

### ğŸ’¡ SHAP Explanations

Understand model decisions with:
- Feature contribution waterfall plots
- Class-specific explanations (positive class)
- Robust visualization for ensemble models

---

## ğŸ”„ Retraining & Tuning

### Full Retraining
Access from sidebar to rebuild models with updated data.

### Quick Parameter Tuning
Adjust hyperparameters without full retraining:
- **RandomForest:** n_estimators, max_depth, min_samples_split
- **LightGBM:** n_estimators, learning_rate, max_depth

---

## ğŸ§ª Testing

### Generate Test Data

```bash
python generate_test_data.py
```

Creates four test CSV files:

| File | Description |
|------|-------------|
| `realistic_exoplanet_test_data.csv` | Real-world parameter distributions |
| `simple_exoplanet_test_data.csv` | Basic test cases |
| `large_exoplanet_test_data.csv` | High-volume testing |
| `edge_case_exoplanet_test_data.csv` | Boundary conditions |

Upload via **Make Predictions â†’ Upload CSV**

---

## ğŸ“Š Training Pipeline

Execute complete training workflow:

```bash
python train_models.py
```

**Outputs:**
- ğŸ¤– Model files: `exoplanet_models_*.joblib`
- ğŸ“ˆ Performance plot: `reports/model_performance_report.png`
- ğŸ“„ Text report: `reports/performance_report.txt`

**Process includes:**
1. Data loading and preprocessing
2. Cross-validation (5-fold)
3. Hold-out set evaluation
4. External validation (TOI & K2)
5. Model serialization

---

## ğŸ› ï¸ Troubleshooting Guide

| Issue | Solution |
|-------|----------|
| **Models not loaded** | Refresh page or run `train_models.py` |
| **SimpleImputer error** | Visit "Make Predictions" page once |
| **External validation empty** | Verify filenames and label columns |
| **Feature mismatch** | Check dataset format matches requirements |
| **Memory errors** | Reduce batch size or use smaller datasets |

---

## ğŸŒŸ Use Cases

- ğŸ”­ **Research:** Validate exoplanet candidates
- ğŸ“š **Education:** Learn ML in astronomy
- ğŸ§ª **Development:** Test detection algorithms
- ğŸ“Š **Analysis:** Compare model performance
- ğŸš€ **Production:** Deploy automated screening

---

## ğŸ“š References & Acknowledgments

This project builds upon NASA's publicly available exoplanet datasets and recent advances in astronomical machine learning.

### Data Sources
- [NASA Exoplanet Archive](https://exoplanetarchive.ipst.edu/)
- Kepler/K2 Mission Data
- TESS Mission Data

### Related Technologies
- TransitDot Analytics
- ORACLE Detection Framework
- JWST Readiness Scoring

**External Links:**
- [NEOSSat Satellite](https://www.asc-csa.gc.ca/eng/satellites/neossat/)
- [CSA Data Portal](https://donnees-data.asc-csa.gc.ca/en/dataset/9ae3e718-8b6d-40b7-8aa4-858f00e84b30)
- [James Webb Space Telescope](https://www.asc-csa.gc.ca/eng/satellites/jwst/about.asp)

---

## ğŸ“„ License

```
MIT License

Copyright (c) 2025 NASA Exoplanet Detection AI

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues or pull requests.

### Development Setup
1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

---

## ğŸ“§ Contact & Support

For questions, suggestions, or collaboration opportunities:
- ğŸ“« Open an issue on GitHub
- ğŸ’¬ Join discussions in the repository

---

<div align="center">

**Made with â¤ï¸ for the astronomical community**

â­ Star this repository if you find it helpful!

</div>
