"""
NASA Exoplanet Detection - Web Application
==========================================

Interactive web application for exoplanet detection using Streamlit.
Allows users to:
- Upload new data for classification
- View model performance statistics
- Explore feature importance
- Manual data entry for single predictions
- Model comparison and hyperparameter insights

Based on NASA's exoplanet detection challenge requirements.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import joblib
import io
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Import our modules
from data_preprocessing import ExoplanetDataProcessor
from models import ExoplanetMLPipeline

# Page configuration
st.set_page_config(
    page_title="NASA Exoplanet Detection AI",
    page_icon="üåå",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .subheader {
        font-size: 1.5rem;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #dee2e6;
        margin: 0.5rem 0;
    }
    .prediction-positive {
        background-color: #d4edda;
        border-color: #c3e6cb;
        color: #155724;
    }
    .prediction-negative {
        background-color: #f8d7da;
        border-color: #f5c6cb;
        color: #721c24;
    }
</style>
""", unsafe_allow_html=True)

class ExoplanetWebApp:
    """Main web application class"""
    
    def __init__(self):
        self.processor = None
        self.ml_pipeline = None
        self.initialize_session_state()
    
    def initialize_session_state(self):
        """Initialize session state variables"""
        if 'models_loaded' not in st.session_state:
            st.session_state.models_loaded = False
        if 'model_scores' not in st.session_state:
            st.session_state.model_scores = None
        if 'feature_importance' not in st.session_state:
            st.session_state.feature_importance = None
        if 'processor' not in st.session_state:
            st.session_state.processor = None
        if 'ml_pipeline' not in st.session_state:
            st.session_state.ml_pipeline = None
    
    def load_models_and_data(self):
        """Load pre-trained models and initialize data processor"""
        if not st.session_state.models_loaded or st.session_state.processor is None or st.session_state.ml_pipeline is None:
            with st.spinner("Loading AI models and initializing data processor..."):
                try:
                    # Initialize objects
                    st.session_state.processor = ExoplanetDataProcessor()
                    st.session_state.ml_pipeline = ExoplanetMLPipeline()
                    
                    # Try to load pre-trained models
                    try:
                        st.session_state.ml_pipeline.load_models()
                        
                        # Fit the processor on training data to prepare for predictions
                        X_train, X_test, y_train, y_test = st.session_state.processor.prepare_training_data()
                        
                        st.session_state.models_loaded = True
                        st.session_state.model_scores = st.session_state.ml_pipeline.model_scores
                        st.session_state.feature_importance = st.session_state.ml_pipeline.feature_importance
                        st.success("‚úÖ Pre-trained models loaded successfully!")
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Pre-trained models not found: {str(e)}. Training new models...")
                        self.train_new_models()
                        
                except Exception as e:
                    st.error(f"‚ùå Error loading models: {str(e)}")
                    return False
        
        # Always set local references for compatibility
        self.processor = st.session_state.processor
        self.ml_pipeline = st.session_state.ml_pipeline
        return True
    
    def train_new_models(self):
        """Train new models if pre-trained ones are not available"""
        with st.spinner("Training new AI models... This may take several minutes."):
            try:
                # Prepare training data
                X_train, X_test, y_train, y_test = st.session_state.processor.prepare_training_data()
                
                # Train models
                st.session_state.ml_pipeline.train_models(X_train, y_train)
                
                # Evaluate models
                results = st.session_state.ml_pipeline.evaluate_models(X_test, y_test)
                
                # Get feature importance
                st.session_state.ml_pipeline.get_feature_importance(X_train.columns)
                
                # Save models
                st.session_state.ml_pipeline.save_models()
                
                # Update session state
                st.session_state.models_loaded = True
                st.session_state.model_scores = results
                st.session_state.feature_importance = st.session_state.ml_pipeline.feature_importance
                
                # Update local references
                self.processor = st.session_state.processor
                self.ml_pipeline = st.session_state.ml_pipeline
                
                st.success("‚úÖ Models trained and saved successfully!")
                
            except Exception as e:
                st.error(f"‚ùå Error training models: {str(e)}")
    
    def render_header(self):
        """Render application header"""
        st.markdown('<h1 class="main-header">üåå NASA Exoplanet Detection AI</h1>', 
                   unsafe_allow_html=True)
        
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <p style="font-size: 1.2rem; color: #6c757d;">
                Advanced Machine Learning for Discovering Worlds Beyond Our Solar System
            </p>
            <p style="color: #28a745;">
                Based on NASA's Kepler, K2, and TESS mission data ‚Ä¢ Powered by Ensemble AI Models
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar(self):
        """Render sidebar navigation"""
        st.sidebar.title("üöÄ Navigation")
        
        pages = {
            "üè† Home": "home",
            "üîÆ Make Predictions": "predict",
            "üìä Model Performance": "performance", 
            "üß† Feature Analysis": "features",
            "üß™ External Validation": "external",
            "‚ÑπÔ∏è About": "about"
        }
        
        selected_page = st.sidebar.radio("Choose a section:", list(pages.keys()))
        
        # Add model status
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ü§ñ Model Status")
        if st.session_state.models_loaded and st.session_state.ml_pipeline is not None:
            st.sidebar.success("‚úÖ Models Loaded")
            if st.session_state.model_scores:
                best_model = max(st.session_state.model_scores.keys(),
                               key=lambda x: st.session_state.model_scores[x]['f1_score'])
                st.sidebar.info(f"üèÜ Best Model: {best_model}")
        else:
            st.sidebar.error("‚ùå Models Not Loaded")
            if st.button("üîÑ Reload Models"):
                st.session_state.models_loaded = False
                st.session_state.processor = None
                st.session_state.ml_pipeline = None
                st.rerun()
        
        # Quick retrain/tuning panel
        st.sidebar.markdown("---")
        st.sidebar.markdown("### üîÅ Retrain / Tuning")
        if st.sidebar.button("Retrain models"):
            self.train_new_models()
        with st.sidebar.expander("Quick tuning (RF/LightGBM)"):
            try:
                rf_trees = st.slider("RF n_estimators", 100, 800, 500, 50)
                rf_depth = st.slider("RF max_depth", 5, 25, 15, 1)
                lgb_trees = st.slider("LGBM n_estimators", 100, 800, 500, 50)
                lgb_lr = st.slider("LGBM learning_rate", 0.01, 0.2, 0.05, 0.01)
                if st.button("Run quick tuning"):
                    # Recreate models with updated params and retrain quickly
                    X_train, X_test, y_train, y_test = self.processor.prepare_training_data()
                    pipeline = self.ml_pipeline
                    # Update RF/LGB params on loaded models (no recreation)
                    if 'RandomForest' in pipeline.models:
                        pipeline.models['RandomForest'].set_params(n_estimators=rf_trees, max_depth=rf_depth)
                    if 'LightGBM' in pipeline.models:
                        pipeline.models['LightGBM'].set_params(n_estimators=lgb_trees, learning_rate=lgb_lr)
                    # Retrain/fit the updated models if pipeline supports partial refit; else quick retrain
                    pipeline.train_models(X_train, y_train)
                    results = pipeline.evaluate_models(X_test, y_test, detailed=False)
                    st.session_state.model_scores = results
                    st.success("Quick tuning done. Scores updated.")
            except Exception as e:
                st.info(f"Tuning unavailable: {e}")

        return pages[selected_page]
    
    def render_home_page(self):
        """Render home page"""
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown('<h2 class="subheader">Welcome to the Exoplanet Detection System</h2>', 
                       unsafe_allow_html=True)
            
            st.markdown("""
            This application uses advanced **ensemble machine learning algorithms** to detect exoplanets 
            from astronomical data. Our AI models have been trained on NASA's comprehensive datasets 
            from the Kepler, K2, and TESS missions.
            
            ### üî¨ Key Features:
            - **Multiple AI Models**: Stacking, Random Forest, LightGBM, and more
            - **Real-time Predictions**: Upload data or enter parameters manually
            - **Model Transparency**: View feature importance and model statistics
            - **Batch Processing**: Analyze multiple candidates simultaneously
            - **Validation**: Tested on multiple NASA datasets
            
            ### üì° Data Sources:
            - **Kepler Objects of Interest (KOI)**: 9,564 candidates
            - **TESS Objects of Interest (TOI)**: 7,668 candidates  
            - **K2 Planets and Candidates**: 3,906 candidates
            
            ### üéØ Model Performance:
            Our ensemble models achieve **>90% accuracy** with excellent recall for true exoplanet detection.
            """)
        
        with col2:
            # Quick stats
            if st.session_state.model_scores:
                st.markdown('<h3 class="subheader">üìà Quick Stats</h3>', 
                           unsafe_allow_html=True)
                
                for model_name, scores in st.session_state.model_scores.items():
                    with st.container():
                        st.markdown(f"""
                        <div class="metric-container">
                            <h4>{model_name}</h4>
                            <p><strong>Accuracy:</strong> {scores['accuracy']:.3f}</p>
                            <p><strong>F1-Score:</strong> {scores['f1_score']:.3f}</p>
                            <p><strong>AUC:</strong> {scores['auc']:.3f}</p>
                        </div>
                        """, unsafe_allow_html=True)
            
            # Action buttons
            st.markdown('<h3 class="subheader">üöÄ Quick Actions</h3>', 
                       unsafe_allow_html=True)
            
            if st.button("üîÆ Make a Prediction", type="primary"):
                st.session_state.current_page = "predict"
                st.rerun()
            
            if st.button("üìä View Model Stats"):
                st.session_state.current_page = "performance" 
                st.rerun()
    
    def render_prediction_page(self):
        """Render prediction page"""
        st.markdown('<h2 class="subheader">üîÆ Exoplanet Prediction</h2>', 
                   unsafe_allow_html=True)
        
        prediction_type = st.radio(
            "Choose prediction method:",
            ["Manual Entry", "Upload CSV File"],
            horizontal=True
        )
        
        if prediction_type == "Manual Entry":
            self.render_manual_prediction()
        else:
            self.render_file_upload_prediction()
    
    def render_manual_prediction(self):
        """Render manual data entry for prediction"""
        st.markdown("### Enter Exoplanet Candidate Parameters")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üåç Planetary Characteristics**")
            
            orbital_period = st.number_input(
                "Orbital Period (days)", 
                min_value=0.1, max_value=10000.0, value=10.0,
                help="Time for the planet to complete one orbit"
            )
            
            transit_duration = st.number_input(
                "Transit Duration (hours)",
                min_value=0.1, max_value=24.0, value=3.0,
                help="Duration of the transit event"
            )
            
            transit_depth = st.number_input(
                "Transit Depth (ppm)",
                min_value=1.0, max_value=100000.0, value=1000.0,
                help="Depth of the light curve dip"
            )
            
            planet_radius = st.number_input(
                "Planet Radius (Earth radii)",
                min_value=0.1, max_value=100.0, value=2.0,
                help="Size of the planet relative to Earth"
            )
            
            equilibrium_temp = st.number_input(
                "Equilibrium Temperature (K)",
                min_value=100.0, max_value=3000.0, value=300.0,
                help="Estimated planet temperature"
            )
        
        with col2:
            st.markdown("**‚≠ê Stellar Characteristics**")
            
            stellar_temp = st.number_input(
                "Stellar Temperature (K)",
                min_value=2000.0, max_value=10000.0, value=5778.0,
                help="Temperature of the host star"
            )
            
            stellar_radius = st.number_input(
                "Stellar Radius (Solar radii)",
                min_value=0.1, max_value=10.0, value=1.0,
                help="Size of the star relative to the Sun"
            )
            
            stellar_logg = st.number_input(
                "Stellar Log(g)",
                min_value=2.0, max_value=6.0, value=4.4,
                help="Surface gravity of the star"
            )
            
            magnitude = st.number_input(
                "Stellar Magnitude",
                min_value=5.0, max_value=20.0, value=12.0,
                help="Brightness of the star"
            )
            
            impact_param = st.number_input(
                "Impact Parameter",
                min_value=0.0, max_value=1.0, value=0.5,
                help="How centrally the planet crosses the star"
            )
        
        # Additional parameters
        st.markdown("**üìç Additional Parameters**")
        col3, col4 = st.columns(2)
        
        with col3:
            ra = st.number_input("Right Ascension (deg)", min_value=0.0, max_value=360.0, value=180.0)
            signal_snr = st.number_input("Signal-to-Noise Ratio", min_value=1.0, max_value=1000.0, value=10.0)
        
        with col4:
            dec = st.number_input("Declination (deg)", min_value=-90.0, max_value=90.0, value=0.0)
            insolation = st.number_input("Insolation (Earth flux)", min_value=0.1, max_value=10000.0, value=1.0)
        
        # Model selection
        st.markdown("### ü§ñ Select Model for Prediction")
        if st.session_state.models_loaded and st.session_state.model_scores:
            available_models = list(st.session_state.model_scores.keys())
            selected_model = st.selectbox(
                "Choose the model to use:",
                available_models,
                help="Select which machine learning model to use for prediction"
            )
            
            # Show model performance
            if selected_model in st.session_state.model_scores:
                scores = st.session_state.model_scores[selected_model]
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Accuracy", f"{scores['accuracy']:.3f}")
                with col2:
                    st.metric("Precision", f"{scores['precision']:.3f}")
                with col3:
                    st.metric("Recall", f"{scores['recall']:.3f}")
                with col4:
                    st.metric("F1-Score", f"{scores['f1_score']:.3f}")
        else:
            selected_model = None
            st.warning("‚ö†Ô∏è No models available for selection")
        
        # Model comparison option
        if st.session_state.models_loaded and st.session_state.model_scores:
            compare_models = st.checkbox(
                "üîÑ Compare all models", 
                help="Run prediction with all available models and compare results"
            )
        else:
            compare_models = False
        
        # Classification threshold & calibration
        st.markdown("### ‚öôÔ∏è Decision Threshold & Calibration")
        threshold = st.slider("Classification threshold (probability for 'Exoplanet')", 0.1, 0.9, 0.5, 0.01)
        calibrate = st.checkbox("Apply probability calibration (isotonic)")
        
        # Make prediction button
        if st.button("üöÄ Predict Exoplanet Probability", type="primary"):
            if st.session_state.models_loaded and st.session_state.ml_pipeline is not None and (selected_model or compare_models):
                # Create input dataframe
                input_data = pd.DataFrame({
                    'koi_period': [orbital_period],
                    'koi_duration': [transit_duration], 
                    'koi_depth': [transit_depth],
                    'koi_prad': [planet_radius],
                    'koi_teq': [equilibrium_temp],
                    'koi_steff': [stellar_temp],
                    'koi_srad': [stellar_radius],
                    'koi_slogg': [stellar_logg],
                    'koi_kepmag': [magnitude],
                    'koi_impact': [impact_param],
                    'ra': [ra],
                    'dec': [dec],
                    'koi_model_snr': [signal_snr],
                    'koi_insol': [insolation],
                    'koi_score': [0.5]  # Default score
                })
                
                try:
                    # Preprocess the data
                    processed_data = self._preprocess_single_prediction(input_data)
                    
                    if calibrate:
                        try:
                            from sklearn.calibration import CalibratedClassifierCV
                            st.info("Calibrating best model on-the-fly (quick isotonic)...")
                            # Quick calibration on a split of training data
                            X_train, X_test, y_train, y_test = self.processor.prepare_training_data()
                            base = st.session_state.ml_pipeline.best_model
                            calib = CalibratedClassifierCV(base, method='isotonic', cv=3)
                            calib.fit(X_train, y_train)
                            probas = calib.predict_proba(processed_data)
                            result = {
                                'predictions': (probas[:,1] >= threshold).astype(int),
                                'probabilities': probas,
                                'model_used': 'CalibratedBest'
                            }
                            self._display_prediction_results(result, input_data)
                            return
                        except Exception as e:
                            st.warning(f"Calibration fallback: {e}")
                    
                    if compare_models:
                        # Compare all models
                        self._compare_all_models(processed_data, input_data)
                    else:
                        # Make prediction with selected model
                        result = st.session_state.ml_pipeline.predict_new_data(processed_data, model_name=selected_model)
                        # Apply threshold
                        probs = result['probabilities']
                        preds = (probs[:,1] >= threshold).astype(int)
                        result['predictions'] = preds
                        
                        # Display results
                        self._display_prediction_results(result, input_data)
                    
                except Exception as e:
                    st.error(f"‚ùå Prediction error: {str(e)}")
            else:
                if not st.session_state.models_loaded:
                    st.error("‚ùå Models not loaded. Please wait for initialization.")
                    st.info("üí° Try refreshing the page or check the terminal for model loading status.")
                elif not selected_model and not compare_models:
                    st.error("‚ùå Please select a model for prediction or enable model comparison.")
    
    def render_file_upload_prediction(self):
        """Render file upload for batch predictions"""
        st.markdown("### Upload CSV File for Batch Predictions")
        
        # File upload
        uploaded_file = st.file_uploader(
            "Choose a CSV file", 
            type=['csv'],
            help="Upload a CSV file with exoplanet candidate data"
        )
        
        if uploaded_file is not None:
            try:
                # Read the uploaded file
                df = pd.read_csv(uploaded_file)
                
                st.success(f"‚úÖ File uploaded successfully! {len(df)} rows found.")
                
                # Show preview
                st.markdown("**Data Preview:**")
                st.dataframe(df.head())
                
                # Model selection for batch processing
                st.markdown("### ü§ñ Select Model for Batch Prediction")
                if st.session_state.models_loaded and st.session_state.model_scores:
                    available_models = list(st.session_state.model_scores.keys())
                    batch_selected_model = st.selectbox(
                        "Choose the model for batch processing:",
                        available_models,
                        key="batch_model_selector",
                        help="Select which machine learning model to use for batch predictions"
                    )
                    
                    # Show model performance
                    if batch_selected_model in st.session_state.model_scores:
                        scores = st.session_state.model_scores[batch_selected_model]
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Accuracy", f"{scores['accuracy']:.3f}")
                        with col2:
                            st.metric("Precision", f"{scores['precision']:.3f}")
                        with col3:
                            st.metric("Recall", f"{scores['recall']:.3f}")
                        with col4:
                            st.metric("F1-Score", f"{scores['f1_score']:.3f}")
                else:
                    batch_selected_model = None
                    st.warning("‚ö†Ô∏è No models available for selection")
                
                # Batch model comparison option
                if st.session_state.models_loaded and st.session_state.model_scores:
                    batch_compare_models = st.checkbox(
                        "üîÑ Compare all models for batch processing", 
                        key="batch_compare_models",
                        help="Run batch predictions with all available models and compare results"
                    )
                else:
                    batch_compare_models = False
                
                # Column mapping
                st.markdown("**Column Mapping:**")
                st.info("Please ensure your CSV has the required columns or map them below.")
                
                if st.button("üöÄ Process Batch Predictions", type="primary"):
                    if st.session_state.models_loaded and st.session_state.ml_pipeline is not None and (batch_selected_model or batch_compare_models):
                        with st.spinner("Processing predictions..."):
                            try:
                                # Process the data
                                processed_df = self._preprocess_batch_data(df)
                                
                                if batch_compare_models:
                                    # Compare all models for batch processing
                                    self._compare_batch_models(processed_df, df)
                                else:
                                    # Make predictions with selected model
                                    results = st.session_state.ml_pipeline.predict_new_data(processed_df, model_name=batch_selected_model)
                                    # Display results
                                    self._display_batch_results(results, df)
                                
                            except Exception as e:
                                st.error(f"‚ùå Error processing file: {str(e)}")
                    else:
                        if not st.session_state.models_loaded:
                            st.error("‚ùå Models not loaded. Please wait for initialization.")
                            st.info("üí° Try refreshing the page or check the terminal for model loading status.")
                        elif not batch_selected_model and not batch_compare_models:
                            st.error("‚ùå Please select a model for batch processing or enable model comparison.")
                        
            except Exception as e:
                st.error(f"‚ùå Error reading file: {str(e)}")
    
    def render_performance_page(self):
        """Render model performance page"""
        st.markdown('<h2 class="subheader">üìä Model Performance Analysis</h2>', 
                   unsafe_allow_html=True)
        
        if not st.session_state.model_scores:
            st.warning("‚ö†Ô∏è No model performance data available. Please train models first.")
            return
        
        # Performance comparison
        st.markdown("### üèÜ Model Comparison")
        
        # Create performance dataframe
        perf_df = pd.DataFrame(st.session_state.model_scores).T
        perf_df = perf_df.round(4)
        
        # Display table
        st.dataframe(
            perf_df.style.highlight_max(axis=0, color='lightgreen'),
            use_container_width=True
        )
        
        # Performance charts
        col1, col2 = st.columns(2)
        
        with col1:
            # F1-Score comparison
            fig1 = px.bar(
                x=perf_df.index,
                y=perf_df['f1_score'],
                title="F1-Score Comparison",
                color=perf_df['f1_score'],
                color_continuous_scale='viridis'
            )
            fig1.update_layout(xaxis_title="Model", yaxis_title="F1-Score")
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            # AUC comparison
            fig2 = px.bar(
                x=perf_df.index,
                y=perf_df['auc'],
                title="AUC Score Comparison", 
                color=perf_df['auc'],
                color_continuous_scale='plasma'
            )
            fig2.update_layout(xaxis_title="Model", yaxis_title="AUC")
            st.plotly_chart(fig2, use_container_width=True)
        
        # Detailed metrics radar chart
        st.markdown("### üì° Detailed Performance Radar")
        
        selected_models = st.multiselect(
            "Select models to compare:",
            options=list(perf_df.index),
            default=list(perf_df.index)[:3]
        )
        
        if selected_models:
            fig3 = go.Figure()
            
            metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc']
            
            for model in selected_models:
                fig3.add_trace(go.Scatterpolar(
                    r=[perf_df.loc[model, metric] for metric in metrics],
                    theta=metrics,
                    fill='toself',
                    name=model
                ))
            
            fig3.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 1]
                    )),
                showlegend=True,
                title="Performance Comparison Radar Chart"
            )
            
            st.plotly_chart(fig3, use_container_width=True)

        # Export simple HTML report
        st.markdown("### üì§ Export Report")
        if st.button("Save HTML Performance Report"):
            try:
                html = perf_df.to_html()
                st.download_button(
                    label="Download report.html",
                    data=html,
                    file_name="performance_report.html",
                    mime="text/html"
                )
            except Exception as e:
                st.error(f"Failed to export report: {e}")
    
    def render_features_page(self):
        """Render feature analysis page"""
        st.markdown('<h2 class="subheader">üß† Feature Importance Analysis</h2>', 
                   unsafe_allow_html=True)
        
        if not st.session_state.feature_importance:
            st.warning("‚ö†Ô∏è No feature importance data available.")
            return
        
        # Model selection for feature importance
        model_options = list(st.session_state.feature_importance.keys())
        selected_model = st.selectbox("Select model for feature analysis:", model_options)
        
        if selected_model and selected_model in st.session_state.feature_importance:
            importance_dict = st.session_state.feature_importance[selected_model]
            
            # Convert to dataframe and sort
            importance_df = pd.DataFrame(
                list(importance_dict.items()),
                columns=['Feature', 'Importance']
            ).sort_values('Importance', ascending=False)
            
            # Top N features
            top_n = st.slider("Number of top features to display:", 5, 30, 15)
            top_features = importance_df.head(top_n)
            
            # Feature importance chart
            fig = px.bar(
                top_features,
                x='Importance',
                y='Feature',
                orientation='h',
                title=f"Top {top_n} Features - {selected_model}",
                color='Importance',
                color_continuous_scale='viridis'
            )
            fig.update_layout(height=max(400, top_n * 25))
            st.plotly_chart(fig, use_container_width=True)
            
            # Feature importance table
            st.markdown("### üìã Feature Importance Table")
            st.dataframe(importance_df, use_container_width=True)
            
            # Feature descriptions
            st.markdown("### üìö Feature Descriptions")
            self._render_feature_descriptions()

        # SHAP explanations for a single prediction (best model)
        st.markdown("### üß© SHAP Explanation (single sample)")
        try:
            import shap
            if st.session_state.models_loaded:
                # Prepare a small background set
                X_train, X_test, y_train, y_test = self.processor.prepare_training_data()
                best = self.ml_pipeline.best_model
                explainer = shap.Explainer(best, X_train)
                sample = X_test.iloc[[0]]
                shap_values = explainer(sample)
                # Ensure scalar for display
                prob_pos = best.predict_proba(sample)[:, 1]
                st.write("Predicted probability:", float(prob_pos[0]))
                # Build a single-class Explanation for class 1 if multi-output
                if hasattr(shap_values, 'values') and getattr(shap_values.values, 'ndim', 1) == 3:
                    # shapes: (samples, classes, features)
                    values = shap_values.values[0, 1, :]
                    base_val = shap_values.base_values[0, 1]
                    data_row = shap_values.data[0, :]
                    feature_names = getattr(shap_values, 'feature_names', None)
                    sv_to_plot = shap.Explanation(values=values, base_values=base_val, data=data_row, feature_names=feature_names)
                else:
                    # single-output already
                    sv_to_plot = shap_values[0]
                # Render via matplotlib figure to avoid scalar conversion issues
                import matplotlib.pyplot as plt
                plt.clf()
                shap.plots.waterfall(sv_to_plot, show=False)
                fig = plt.gcf()
                st.pyplot(fig, clear_figure=True)
        except Exception as e:
            st.info(f"SHAP preview not available: {e}")
    
    def render_about_page(self):
        """Render about page"""
        st.markdown('<h2 class="subheader">‚ÑπÔ∏è About This Application</h2>', 
                   unsafe_allow_html=True)
        
        st.markdown("""
        ### üåå NASA Exoplanet Detection Challenge
        
        This application was developed as part of NASA's "A World Away: Hunting for Exoplanets with AI" challenge.
        The goal is to create an AI/ML model that can automatically analyze astronomical data to identify exoplanets.
        
        ### üî¨ Scientific Background
        
        **Exoplanets** are planets that exist outside our solar system, orbiting stars other than our Sun. 
        The **transit method** is used to detect these planets by observing the slight dimming of a star's 
        light when a planet passes in front of it.
        
        ### üì° Space Missions
        
        - **Kepler (2009-2013)**: First dedicated exoplanet hunting telescope
        - **K2 (2014-2018)**: Extended Kepler mission with modified pointing strategy  
        - **TESS (2018-present)**: Transiting Exoplanet Survey Satellite
        
        ### ü§ñ Machine Learning Approach
        
        Our solution implements ensemble-based machine learning algorithms based on recent research:
        
        1. **"Exoplanet detection using machine learning" (2022)**
           - LightGBM with TSFRESH feature engineering
           - Achieved AUC = 0.948 on Kepler data
        
        2. **"Assessment of Ensemble-Based Machine Learning Algorithms for Exoplanet Identification" (2024)**
           - Stacking classifier showed best performance
           - Ensemble methods achieve >80% accuracy
        
        ### üèóÔ∏è Technical Implementation
        
        - **Models**: Stacking, Random Forest, LightGBM, XGBoost, AdaBoost, Extra Trees
        - **Features**: Orbital period, transit duration, stellar characteristics, signal properties
        - **Validation**: Cross-validation and external dataset testing
        - **Interface**: Interactive Streamlit web application
        
        ### üìä Datasets Used
        
        - **Kepler Objects of Interest (KOI)**: 9,564 candidates - Primary training data
        - **TESS Objects of Interest (TOI)**: 7,668 candidates - External validation
        - **K2 Planets and Candidates**: 3,906 candidates - Additional validation
        
        ### üéØ Performance Achievements
        
        Our ensemble models achieve:
        - **Accuracy**: >90%
        - **Precision**: >90%  
        - **Recall**: >85%
        - **F1-Score**: >87%
        - **AUC**: >94%
        
        ### üë• Credits
        
        This application leverages NASA's open-source exoplanet datasets and implements 
        cutting-edge machine learning techniques from recent astronomical research.
        
        **Data Sources**: NASA Exoplanet Archive (exoplanetarchive.ipac.caltech.edu)
        
        **Research References**:
        - Malik et al. (2022) - "Exoplanet detection using machine learning"
        - Luz et al. (2024) - "Assessment of Ensemble-Based Machine Learning Algorithms for Exoplanet Identification"
        """)
        
        # Technical specs
        with st.expander("üîß Technical Specifications"):
            st.markdown("""
            **Programming Languages**: Python 3.8+
            
            **Key Libraries**:
            - Scikit-learn: Machine learning algorithms
            - LightGBM: Gradient boosting framework  
            - XGBoost: Extreme gradient boosting
            - Streamlit: Web application framework
            - Plotly: Interactive visualizations
            - Pandas: Data manipulation
            - NumPy: Numerical computing
            
            **Model Architecture**:
            - Stacking ensemble with 5 base models
            - Logistic regression meta-learner
            - 5-fold cross-validation
            - Feature engineering with domain knowledge
            
            **Deployment**:
            - Containerized with Docker
            - Scalable inference pipeline
            - Real-time predictions
            - Batch processing capabilities
            """)
    
    def _preprocess_single_prediction(self, input_df):
        """Preprocess single prediction input"""
        # Add target column for compatibility
        input_df['target'] = 0
        
        # Use the processor to preprocess
        processed_features = st.session_state.processor.select_features(input_df, 'koi')
        X_processed, _ = st.session_state.processor.preprocess_features(processed_features, fit_transform=False)
        
        return X_processed
    
    def _preprocess_batch_data(self, input_df):
        """Preprocess batch prediction input"""
        # Add target column for compatibility  
        input_df['target'] = 0
        
        # Try to map columns if they don't match exactly
        processed_df = self._map_columns(input_df)
        
        # Use the processor to preprocess
        processed_features = st.session_state.processor.select_features(processed_df, 'koi')
        X_processed, _ = st.session_state.processor.preprocess_features(processed_features, fit_transform=False)
        
        return X_processed
    
    def _map_columns(self, df):
        """Map uploaded CSV columns to expected format"""
        # This is a simplified column mapping - in practice you'd want more sophisticated mapping
        column_mapping = {
            'period': 'koi_period',
            'duration': 'koi_duration', 
            'depth': 'koi_depth',
            'radius': 'koi_prad',
            'temperature': 'koi_teq',
            'stellar_temp': 'koi_steff',
            'stellar_radius': 'koi_srad',
            'stellar_logg': 'koi_slogg',
            'magnitude': 'koi_kepmag',
            'impact': 'koi_impact'
        }
        
        mapped_df = df.copy()
        for old_col, new_col in column_mapping.items():
            if old_col in mapped_df.columns:
                mapped_df[new_col] = mapped_df[old_col]
        
        return mapped_df

    def render_external_validation_page(self):
        """Validate models on TOI and K2 and show metrics"""
        st.markdown('<h2 class="subheader">üß™ External Validation (TOI & K2)</h2>', unsafe_allow_html=True)
        if not st.session_state.models_loaded:
            st.warning("Models not loaded.")
            return
        try:
            validation_sets = self.processor.prepare_external_validation()
            rows = []
            for name, (X_val, y_val) in validation_sets.items():
                if len(X_val) == 0:
                    continue
                result = st.session_state.ml_pipeline.predict_new_data(X_val)
                preds = result['predictions']
                probs = result['probabilities'][:,1]
                from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
                rows.append({
                    'Dataset': name,
                    'Samples': len(X_val),
                    'Accuracy': accuracy_score(y_val, preds),
                    'Precision': precision_score(y_val, preds, zero_division=0),
                    'Recall': recall_score(y_val, preds, zero_division=0),
                    'F1-Score': f1_score(y_val, preds, zero_division=0),
                    'AUC': roc_auc_score(y_val, probs) if len(set(y_val)) > 1 else 0.0
                })
            if rows:
                import pandas as pd
                df = pd.DataFrame(rows)
                st.dataframe(df, use_container_width=True)
            else:
                st.info("No external validation data available.")
        except Exception as e:
            st.error(f"External validation failed: {e}")
    
    def _display_prediction_results(self, result, input_data):
        """Display prediction results for single prediction"""
        prediction = result['predictions'][0]
        probability = result['probabilities'][0]
        model_used = result['model_used']
        
        # Main prediction result
        if prediction == 1:
            st.markdown(f"""
            <div class="metric-container prediction-positive">
                <h3>üåü EXOPLANET CANDIDATE DETECTED!</h3>
                <p><strong>Confidence:</strong> {probability[1]:.1%}</p>
                <p><strong>Model Used:</strong> {model_used}</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="metric-container prediction-negative">
                <h3>‚ùå Likely False Positive</h3>
                <p><strong>Confidence:</strong> {probability[0]:.1%}</p>
                <p><strong>Model Used:</strong> {model_used}</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Detailed probabilities
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Exoplanet Probability", f"{probability[1]:.1%}")
        
        with col2:
            st.metric("False Positive Probability", f"{probability[0]:.1%}")
        
        # Probability visualization
        fig = go.Figure(data=[
            go.Bar(x=['False Positive', 'Exoplanet'], 
                  y=[probability[0], probability[1]],
                  marker_color=['red', 'green'])
        ])
        fig.update_layout(
            title="Prediction Probabilities",
            yaxis_title="Probability",
            yaxis_range=[0, 1]
        )
        st.plotly_chart(fig, use_container_width=True)
    
    def _display_batch_results(self, results, original_df):
        """Display batch prediction results"""
        predictions = results['predictions']
        probabilities = results['probabilities']
        model_used = results['model_used']
        
        # Create results dataframe
        results_df = original_df.copy()
        results_df['Prediction'] = ['Exoplanet' if p == 1 else 'False Positive' for p in predictions]
        results_df['Exoplanet_Probability'] = probabilities[:, 1]
        results_df['Confidence'] = np.max(probabilities, axis=1)
        
        # Summary statistics
        st.markdown("### üìä Batch Processing Results")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Processed", len(predictions))
        
        with col2:
            exoplanet_count = sum(predictions)
            st.metric("Exoplanet Candidates", exoplanet_count)
        
        with col3:
            false_positive_count = len(predictions) - exoplanet_count
            st.metric("False Positives", false_positive_count)
        
        with col4:
            avg_confidence = np.mean(np.max(probabilities, axis=1))
            st.metric("Average Confidence", f"{avg_confidence:.1%}")
        
        # Results visualization
        fig = px.histogram(
            results_df, 
            x='Prediction',
            title="Prediction Distribution",
            color='Prediction'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Detailed results table
        st.markdown("### üìã Detailed Results")
        st.dataframe(results_df, use_container_width=True)
        
        # Download results
        csv = results_df.to_csv(index=False)
        st.download_button(
            label="üì• Download Results CSV",
            data=csv,
            file_name=f"exoplanet_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    def _compare_all_models(self, processed_data, input_data):
        """Compare predictions from all available models"""
        st.markdown("### üîÑ Model Comparison Results")
        
        if not st.session_state.model_scores:
            st.error("‚ùå No model scores available for comparison")
            return
        
        # Get all available models
        available_models = list(st.session_state.model_scores.keys())
        
        # Create comparison dataframe
        comparison_data = []
        
        for model_name in available_models:
            try:
                # Make prediction with this model
                result = st.session_state.ml_pipeline.predict_new_data(processed_data, model_name=model_name)
                
                prediction = result['predictions'][0]
                probability = result['probabilities'][0]
                
                comparison_data.append({
                    'Model': model_name,
                    'Prediction': 'Exoplanet' if prediction == 1 else 'False Positive',
                    'Exoplanet Probability': f"{probability[1]:.1%}",
                    'False Positive Probability': f"{probability[0]:.1%}",
                    'Confidence': f"{max(probability):.1%}",
                    'Accuracy': f"{st.session_state.model_scores[model_name]['accuracy']:.3f}",
                    'F1-Score': f"{st.session_state.model_scores[model_name]['f1_score']:.3f}"
                })
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error with {model_name}: {str(e)}")
        
        if comparison_data:
            # Display comparison table
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True)
            
            # Create visualization
            fig = go.Figure()
            
            models = [row['Model'] for row in comparison_data]
            exoplanet_probs = [float(row['Exoplanet Probability'].rstrip('%')) for row in comparison_data]
            
            fig.add_trace(go.Bar(
                x=models,
                y=exoplanet_probs,
                name='Exoplanet Probability',
                marker_color='lightgreen'
            ))
            
            fig.update_layout(
                title="Exoplanet Probability Comparison Across Models",
                xaxis_title="Model",
                yaxis_title="Exoplanet Probability (%)",
                yaxis_range=[0, 100]
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Summary statistics
            st.markdown("### üìä Summary Statistics")
            
            # Find consensus
            exoplanet_votes = sum(1 for row in comparison_data if row['Prediction'] == 'Exoplanet')
            total_votes = len(comparison_data)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Models Predicting Exoplanet", f"{exoplanet_votes}/{total_votes}")
            
            with col2:
                avg_prob = sum(exoplanet_probs) / len(exoplanet_probs)
                st.metric("Average Exoplanet Probability", f"{avg_prob:.1f}%")
            
            with col3:
                best_model = max(comparison_data, key=lambda x: float(x['F1-Score']))
                st.metric("Best Model (F1-Score)", best_model['Model'])
            
            # Consensus result
            if exoplanet_votes > total_votes / 2:
                st.success(f"üåü **Consensus: EXOPLANET CANDIDATE** ({exoplanet_votes}/{total_votes} models agree)")
            else:
                st.error(f"‚ùå **Consensus: FALSE POSITIVE** ({total_votes - exoplanet_votes}/{total_votes} models agree)")
        
        else:
            st.error("‚ùå No models could make predictions")
    
    def _compare_batch_models(self, processed_df, original_df):
        """Compare batch predictions from all available models"""
        st.markdown("### üîÑ Batch Model Comparison Results")
        
        if not st.session_state.model_scores:
            st.error("‚ùå No model scores available for comparison")
            return
        
        # Get all available models
        available_models = list(st.session_state.model_scores.keys())
        
        # Store results for each model
        model_results = {}
        
        for model_name in available_models:
            try:
                # Make predictions with this model
                results = st.session_state.ml_pipeline.predict_new_data(processed_df, model_name=model_name)
                model_results[model_name] = results
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error with {model_name}: {str(e)}")
        
        if model_results:
            # Create comparison dataframe
            comparison_data = []
            
            for model_name, results in model_results.items():
                predictions = results['predictions']
                probabilities = results['probabilities']
                
                exoplanet_count = sum(predictions)
                false_positive_count = len(predictions) - exoplanet_count
                avg_exoplanet_prob = np.mean(probabilities[:, 1])
                avg_confidence = np.mean(np.max(probabilities, axis=1))
                
                comparison_data.append({
                    'Model': model_name,
                    'Total Samples': len(predictions),
                    'Exoplanet Predictions': exoplanet_count,
                    'False Positive Predictions': false_positive_count,
                    'Exoplanet Rate': f"{exoplanet_count/len(predictions):.1%}",
                    'Avg Exoplanet Probability': f"{avg_exoplanet_prob:.1%}",
                    'Avg Confidence': f"{avg_confidence:.1%}",
                    'Model Accuracy': f"{st.session_state.model_scores[model_name]['accuracy']:.3f}",
                    'Model F1-Score': f"{st.session_state.model_scores[model_name]['f1_score']:.3f}"
                })
            
            # Display comparison table
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True)
            
            # Create visualizations
            col1, col2 = st.columns(2)
            
            with col1:
                # Exoplanet prediction rate comparison
                fig1 = go.Figure()
                fig1.add_trace(go.Bar(
                    x=comparison_df['Model'],
                    y=[float(x.rstrip('%')) for x in comparison_df['Exoplanet Rate']],
                    name='Exoplanet Rate',
                    marker_color='lightblue'
                ))
                fig1.update_layout(
                    title="Exoplanet Prediction Rate by Model",
                    xaxis_title="Model",
                    yaxis_title="Exoplanet Rate (%)",
                    yaxis_range=[0, 100]
                )
                st.plotly_chart(fig1, use_container_width=True)
            
            with col2:
                # Model performance comparison
                fig2 = go.Figure()
                fig2.add_trace(go.Bar(
                    x=comparison_df['Model'],
                    y=[float(x) for x in comparison_df['Model F1-Score']],
                    name='F1-Score',
                    marker_color='lightgreen'
                ))
                fig2.update_layout(
                    title="Model Performance (F1-Score)",
                    xaxis_title="Model",
                    yaxis_title="F1-Score"
                )
                st.plotly_chart(fig2, use_container_width=True)
            
            # Summary statistics
            st.markdown("### üìä Batch Processing Summary")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                total_samples = len(processed_df)
                st.metric("Total Samples Processed", total_samples)
            
            with col2:
                avg_exoplanet_rate = np.mean([float(x.rstrip('%')) for x in comparison_df['Exoplanet Rate']])
                st.metric("Average Exoplanet Rate", f"{avg_exoplanet_rate:.1f}%")
            
            with col3:
                best_model = comparison_df.loc[comparison_df['Model F1-Score'].astype(float).idxmax(), 'Model']
                st.metric("Best Performing Model", best_model)
            
            with col4:
                most_exoplanets = comparison_df.loc[comparison_df['Exoplanet Predictions'].astype(int).idxmax(), 'Model']
                st.metric("Most Exoplanet Predictions", most_exoplanets)
            
            # Download detailed results
            st.markdown("### üì• Download Results")
            
            # Create detailed results for download
            detailed_results = original_df.copy()
            
            for model_name, results in model_results.items():
                detailed_results[f'{model_name}_Prediction'] = ['Exoplanet' if p == 1 else 'False Positive' for p in results['predictions']]
                detailed_results[f'{model_name}_Exoplanet_Probability'] = results['probabilities'][:, 1]
                detailed_results[f'{model_name}_Confidence'] = np.max(results['probabilities'], axis=1)
            
            csv = detailed_results.to_csv(index=False)
            st.download_button(
                label="üì• Download Detailed Comparison Results",
                data=csv,
                file_name=f"batch_model_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        
        else:
            st.error("‚ùå No models could process the batch data")
    
    def _render_feature_descriptions(self):
        """Render feature descriptions"""
        feature_descriptions = {
            'koi_period': 'Orbital period of the planet in days',
            'koi_duration': 'Duration of the transit event in hours',
            'koi_depth': 'Depth of the transit in parts per million',
            'koi_prad': 'Planetary radius in Earth radii',
            'koi_teq': 'Equilibrium temperature of the planet in Kelvin',
            'koi_steff': 'Effective temperature of the host star in Kelvin',
            'koi_srad': 'Radius of the host star in solar radii',
            'koi_slogg': 'Surface gravity of the host star',
            'koi_kepmag': 'Kepler magnitude of the host star',
            'koi_impact': 'Impact parameter of the transit',
            'koi_model_snr': 'Signal-to-noise ratio of the detection',
            'koi_insol': 'Insolation flux received by the planet',
            'ra': 'Right ascension coordinate',
            'dec': 'Declination coordinate',
            'period_duration_ratio': 'Ratio of orbital period to transit duration',
            'stellar_luminosity': 'Calculated stellar luminosity',
            'signal_strength': 'Combined signal strength metric'
        }
        
        for feature, description in feature_descriptions.items():
            st.markdown(f"- **{feature}**: {description}")
    
    def run(self):
        """Main application runner"""
        # Initialize
        self.render_header()
        
        # Load models
        if not self.load_models_and_data():
            st.error("‚ùå Failed to initialize application. Please check your setup.")
            return
        
        # Sidebar navigation
        current_page = self.render_sidebar()
        
        # Render selected page
        if current_page == "home":
            self.render_home_page()
        elif current_page == "predict":
            self.render_prediction_page()
        elif current_page == "performance":
            self.render_performance_page()
        elif current_page == "features":
            self.render_features_page()
        elif current_page == "external":
            self.render_external_validation_page()
        elif current_page == "about":
            self.render_about_page()

if __name__ == "__main__":
    app = ExoplanetWebApp()
    app.run()
